{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Documents\\prob_recession_bolivia\\recession_bolivia\\recession_bolivia\\main\n"
     ]
    }
   ],
   "source": [
    "# 0. Import libraries and set working directory ######################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#from . import proc_target as ut\n",
    "import proc_target as ut\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isocode</th>\n",
       "      <th>period</th>\n",
       "      <th>coup</th>\n",
       "      <th>ons_coup_2</th>\n",
       "      <th>ons_coup_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USA</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FRA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isocode  period  coup  ons_coup_2  ons_coup_3\n",
       "0      USA       1     0         1.0         1.0\n",
       "1      USA       2     0         1.0         1.0\n",
       "2      USA       3     1         NaN         NaN\n",
       "3      USA       4     0         0.0         NaN\n",
       "4      USA       5     0         NaN         NaN\n",
       "5      USA       6     0         NaN         NaN\n",
       "6      FRA       1     0         0.0         0.0\n",
       "7      FRA       2     0         0.0         1.0\n",
       "8      FRA       3     0         1.0         NaN\n",
       "9      FRA       4     0         NaN         NaN\n",
       "10     FRA       5     1         NaN         NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onset_in_target_zero(x: pd.Series, p: int) -> pd.Series:\n",
    "    y = pd.Series(np.nan, index=x.index)\n",
    "    for i in range(len(x)):\n",
    "        if i + p < len(x) and x.iloc[i] == 0:\n",
    "            if 1 in x.iloc[i+1:i+1+p].values:\n",
    "                y.iloc[i] = 1\n",
    "            else:\n",
    "                y.iloc[i] = 0\n",
    "    return y\n",
    "\n",
    "# Example DataFrame\n",
    "df_proof = pd.DataFrame({\n",
    "    'isocode': ['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'FRA', 'FRA', 'FRA', 'FRA', 'FRA'],\n",
    "    'period': [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5],\n",
    "    'coup': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "})\n",
    "\n",
    "#Apply the function for different horizons\n",
    "horizons = [2, 3]\n",
    "for h in horizons:\n",
    "    df_proof[f'ons_coup_{h}'] = df_proof.groupby('isocode')['coup'].transform(lambda x: onset_in_target_zero(x, h)).reset_index(level=0, drop=True)\n",
    "df_proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isocode</th>\n",
       "      <th>period</th>\n",
       "      <th>coup</th>\n",
       "      <th>ons_coup_2</th>\n",
       "      <th>ons_coup_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USA</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FRA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FRA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isocode  period  coup  ons_coup_2  ons_coup_3\n",
       "0      USA       1     0         1.0         1.0\n",
       "1      USA       2     0         1.0         1.0\n",
       "2      USA       3     1         NaN         NaN\n",
       "3      USA       4     0         0.0         NaN\n",
       "4      USA       5     0         NaN         NaN\n",
       "5      USA       6     0         NaN         NaN\n",
       "6      FRA       1     0         0.0         0.0\n",
       "7      FRA       2     0         0.0         1.0\n",
       "8      FRA       3     0         1.0         NaN\n",
       "9      FRA       4     0         NaN         NaN\n",
       "10     FRA       5     1         NaN         NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def onset_in_target_zero(x: pd.Series, p: int) -> pd.Series:\n",
    "    y = pd.Series(np.nan, index=x.index)\n",
    "    for i in range(len(x)):\n",
    "        if i + p < len(x) and x.iloc[i] == 0:\n",
    "            if 1 in x.iloc[i+1:i+1+p].values:\n",
    "                y.iloc[i] = 1\n",
    "            else:\n",
    "                y.iloc[i] = 0\n",
    "    return y\n",
    "\n",
    "# Example DataFrame\n",
    "df_proof = pd.DataFrame({\n",
    "    'isocode': ['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'FRA', 'FRA', 'FRA', 'FRA', 'FRA'],\n",
    "    'period': [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5],\n",
    "    'coup': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "})\n",
    "\n",
    "#Apply the function for different horizons\n",
    "horizons = [2, 3]\n",
    "for h in horizons:\n",
    "    df_proof[f'ons_coup_{h}'] = df_proof.groupby('isocode')['coup'].transform(lambda x: onset_in_target_zero(x, h)).reset_index(level=0, drop=True)\n",
    "df_proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onset_in_target_zero(x: pd.Series, p: int) -> pd.Series:\n",
    "    y = pd.Series(np.nan, index=x.index)\n",
    "    for i in range(len(x)):\n",
    "        if i + p < len(x) and x.iloc[i] == 0:\n",
    "            if 1 in x.iloc[i+1:i+1+p].values:\n",
    "                y.iloc[i] = 1\n",
    "            else:\n",
    "                y.iloc[i] = 0\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>coup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  coup\n",
       "0        1     0\n",
       "1        2     0\n",
       "2        3     1\n",
       "3        4     0\n",
       "4        5     0\n",
       "5        6     0\n",
       "6        7     1\n",
       "7        8     0\n",
       "8        9     0\n",
       "9       10     0\n",
       "10      11     1\n",
       "11      12     0\n",
       "12      13     0\n",
       "13      14     1\n",
       "14      15     0\n",
       "15      16     0\n",
       "16      17     0\n",
       "17      18     1\n",
       "18      19     0\n",
       "19      20     0\n",
       "20      21     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example DataFrame\n",
    "df_proof = pd.DataFrame({\n",
    "    #'isocode': ['USA', 'USA', 'USA', 'USA', 'USA', 'USA', 'FRA', 'FRA', 'FRA', 'FRA', 'FRA'],\n",
    "    'period': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14,15,16,17,18,19,20,21],\n",
    "    'coup': [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
    "})\n",
    "\n",
    "df_proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>coup</th>\n",
       "      <th>ons_coup_2</th>\n",
       "      <th>ons_coup_3</th>\n",
       "      <th>ons_coup_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  coup  ons_coup_2  ons_coup_3  ons_coup_4\n",
       "0        1     0         1.0         1.0         1.0\n",
       "1        2     0         1.0         1.0         1.0\n",
       "2        3     1         NaN         NaN         NaN\n",
       "3        4     0         0.0         1.0         1.0\n",
       "4        5     0         1.0         1.0         1.0\n",
       "5        6     0         1.0         1.0         1.0\n",
       "6        7     1         NaN         NaN         NaN\n",
       "7        8     0         0.0         1.0         1.0\n",
       "8        9     0         1.0         1.0         1.0\n",
       "9       10     0         1.0         1.0         1.0\n",
       "10      11     1         NaN         NaN         NaN\n",
       "11      12     0         1.0         1.0         1.0\n",
       "12      13     0         1.0         1.0         1.0\n",
       "13      14     1         NaN         NaN         NaN\n",
       "14      15     0         0.0         1.0         1.0\n",
       "15      16     0         1.0         1.0         1.0\n",
       "16      17     0         1.0         1.0         1.0\n",
       "17      18     1         NaN         NaN         NaN\n",
       "18      19     0         1.0         NaN         NaN\n",
       "19      20     0         NaN         NaN         NaN\n",
       "20      21     1         NaN         NaN         NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the function for different horizons\n",
    "horizons = [2, 3, 4]\n",
    "for h in horizons:\n",
    "    df_proof[f'ons_coup_{h}'] = df_proof['coup'].transform(lambda x: onset_in_target_zero(x, h)).reset_index(level=0, drop=True)\n",
    "df_proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main data of features set\n",
    "df_feat = pd.read_excel('input/data_selected_sa.xlsx', sheet_name='data1990')\n",
    "df_feat = df_feat.drop(columns='Recession')\n",
    "df_feat.rename(columns={'_date_': 'period'}, inplace=True)\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables do not require conversion into YoY growth rates. They are already expressed in % and are rates\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df_feat_ns = df_feat[['yield10y_2y', 'yield10y_3m', 'vix', 'fed_funds_nom', 'long_term_10y', 'oecd_norm', 'stress_us']]\n",
    "df_feat_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the Variables\n",
    "variables_a_estandarizar = ['yield10y_2y', 'yield10y_3m', 'vix', 'fed_funds_nom', 'long_term_10y', 'oecd_norm', 'stress_us']\n",
    "df_feat_std = df_feat_ns[variables_a_estandarizar].copy()\n",
    "scaler = StandardScaler()\n",
    "df_feat_std[variables_a_estandarizar] = scaler.fit_transform(df_feat_std[variables_a_estandarizar])\n",
    "df_feat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features into growth rates before testing for stationarity, then standardize. \n",
    "colsdrop = ['yield10y_2y', 'yield10y_3m', 'vix', 'fed_funds_nom', 'long_term_10y', 'oecd_norm', 'stress_us', 'ipc_ryc']\n",
    "df_feat = df_feat.drop(columns=colsdrop)\n",
    "df_feat = ut.transform_features(df_feat, 'period')\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat Dataframe Features: Standardized Features and Year-on-Year Rates\n",
    "df_feat_ = pd.concat([df_feat, df_feat_std], axis=1)\n",
    "df_feat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the features data\n",
    "df_feat_.to_csv(f'{path}/output/df_feat.csv', index = False)\n",
    "print(f'saved in {path}/output/df_feat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recession = pd.read_csv('output/df_recession.csv', delimiter=',')\n",
    "df_recession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of Target  \n",
    "#df_recession['Recession'] = df_recession['recession'].apply(lambda x: 1 if x == 0 else 0)\n",
    "#df_recession.drop('recession', axis=1, inplace=True)\n",
    "#df_recession.rename(columns={'Recession': 'recession'}, inplace=True)\n",
    "#df_recession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features - Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest Version Target_Features: Standardized Features and Year-on-Year and Target\n",
    "df_feat_ = df_feat_.drop(columns=['period'])\n",
    "df_dataset = pd.concat([df_recession, df_feat_], axis=1)\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = df_dataset.set_index(\"period\") \n",
    "df_dataset = df_dataset['1991-01-01':'2023-12-01'] # Note: date format: yyyy-mm-dd\n",
    "#df_dataset\n",
    "# Working with onset 0 \n",
    "df_dataset_ons0 = df_dataset.drop(columns=['recession_ons_6', 'recession_ons_12', 'recession_ons_24'])\n",
    "# Working with onset 6 \n",
    "df_dataset_ons6 = df_dataset.drop(columns=['recession',\t'recession_ons_12',\t'recession_ons_24'])\n",
    "# Working with onset 12 \n",
    "df_dataset_ons12 = df_dataset.drop(columns=['recession_ons_6',\t'recession',\t'recession_ons_24'])\n",
    "# Working with onset 24 \n",
    "df_dataset_ons24 = df_dataset.drop(columns=['recession_ons_6',\t'recession_ons_12',\t'recession'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Sector Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Sector Variables\n",
    "#df_dataset_ons0_real = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession',\t'past60_recession', 'past120_recession', \n",
    "#df_dataset_ons0_real = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "#                                        'igae_agri', 'igae_pet', 'igae_ind', 'igae_comu', 'igae_com', 'igae_pub', 'igae_serv', 'ele_dom', 'ele_indgra', \n",
    "#                                        'ele_alum', 'agua', 'ferro', 'aereo', 'ductos', 'prod_gas', 'zinc', 'antimonio']]\n",
    "\n",
    "df_dataset_ons0_real = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                        'igae_pet', 'igae_ind', 'igae_comu', 'igae_pub', 'igae_serv', 'ele_dom', 'ele_indgra', \n",
    "                                        'ele_alum', 'agua', 'prod_gas', 'antimonio']]\n",
    "\n",
    "# Adding Lags of Features Selected\n",
    "#for col in df_dataset_ons0_real.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession',\t'past60_recession', 'past120_recession'], axis=1):\n",
    "for col in df_dataset_ons0_real.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_real['{} {}M lag'.format(col, n)] = df_dataset_ons0_real[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_real = df_dataset_ons0_real.dropna(axis=0)\n",
    "#df_dataset_ons0_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monetary Sector Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monetary Sector Variables\n",
    "#df_dataset_ons0_mon = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', 'past60_recession', 'past120_recession', \n",
    "#                                       'm2_r', 'm3_r', 'm3p_r', 'm4p_r', 'base_r', 'emision_r' ]]\n",
    "\n",
    "df_dataset_ons0_mon = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                       'm2_r', 'm3p_r', 'm4p_r', 'base_r', 'emision_r' ]]\n",
    "\n",
    "# Adding Lags of Features Selected\n",
    "for col in df_dataset_ons0_mon.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_mon['{} {}M lag'.format(col, n)] = df_dataset_ons0_mon[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_mon = df_dataset_ons0_mon.dropna(axis=0)\n",
    "#df_dataset_ons0_mon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prices index an Exchange Rate Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prices index an Exchange Rate Index\n",
    "#df_dataset_ons0_pxr = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', 'past60_recession', 'past120_recession', \n",
    "#                                       'ipc_ali',  'ipc_pvc', 'ipc_viv', 'ipc_bsd', 'ipc_edu', 'itcr',  'itcr_arg', 'itcr_bra', 'itcr_chl', 'itcr_col', 'itcr_zeu' ]]\n",
    "\n",
    "df_dataset_ons0_pxr = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                       'ipc_pvc', 'ipc_viv', 'ipc_bsd', 'ipc_edu', 'itcr',  'itcr_arg', 'itcr_bra', 'itcr_chl', 'itcr_col']]\n",
    "\n",
    "# Adding Lags of Features Selected\n",
    "for col in df_dataset_ons0_pxr.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_pxr['{} {}M lag'.format(col, n)] = df_dataset_ons0_pxr[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_pxr = df_dataset_ons0_pxr.dropna(axis=0)\n",
    "#df_dataset_ons0_pxr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commodities Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commodities Prices\n",
    "#df_dataset_ons0_pex = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', 'past60_recession', 'past120_recession', \n",
    "#                                       'p_gas', 'p_soya_sem', 'p_soya_act', 'p_soya_hrn', 'p_banana', 'p_cobre', 'p_estano', 'p_zinc', 'p_oro']]\n",
    "\n",
    "df_dataset_ons0_pex = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                       'p_gas', 'p_soya_sem', 'p_soya_act', 'p_soya_hrn', 'p_banana', 'p_cobre', 'p_estano', 'p_zinc']]\n",
    "\n",
    "# Adding Lags of Features Selected\n",
    "for col in df_dataset_ons0_pex.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_pex['{} {}M lag'.format(col, n)] = df_dataset_ons0_pex[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_pex = df_dataset_ons0_pex.dropna(axis=0)\n",
    "#df_dataset_ons0_pex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiscal Sector Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiscal Sector Variables\n",
    "#df_dataset_ons0_fis = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', 'past60_recession', 'past120_recession', \n",
    "#                                       'itri', 'iint', 'iadu', 'ioct', 'gsep', 'gbys', 'gint', 'gcap']]\n",
    "\n",
    "df_dataset_ons0_fis = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                       'itri', 'iint', 'iadu', 'gsep', 'gbys', 'gint', 'gcap']]\n",
    "\n",
    "# Adding Lags of Features Selected\n",
    "for col in df_dataset_ons0_fis.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_fis['{} {}M lag'.format(col, n)] = df_dataset_ons0_fis[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_fis = df_dataset_ons0_fis.dropna(axis=0)\n",
    "#df_dataset_ons0_fis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# International Variables\n",
    "#df_dataset_ons0_int = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', 'past60_recession', 'past120_recession', \n",
    "#                                       'yield10y_2y', 'yield10y_3m', 'index_pro_ind', 'vix', 'fed_funds_nom', 'long_term_10y', 'oecd_norm']]\n",
    "\n",
    "df_dataset_ons0_int = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                       'yield10y_2y', 'yield10y_3m', 'index_pro_ind', 'vix', 'fed_funds_nom', 'long_term_10y', 'oecd_norm']]\n",
    "\n",
    "# Adding Lags of Features Selected\n",
    "for col in df_dataset_ons0_int.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_int['{} {}M lag'.format(col, n)] = df_dataset_ons0_int[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_int = df_dataset_ons0_int.dropna(axis=0)\n",
    "#df_dataset_ons0_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all features selected #\n",
    "df_dataset_ons0_all = df_dataset_ons0[['recession', 'recession_lag_1', 'past6_recession', 'past12_recession', \n",
    "                                        'igae_pet', 'igae_ind', 'igae_comu', 'igae_pub', 'igae_serv', 'ele_dom', 'ele_indgra', \n",
    "                                        'ele_alum', 'agua', 'prod_gas', 'antimonio',\n",
    "                                        'm2_r', 'm3p_r', 'm4p_r', 'base_r', 'emision_r',\n",
    "                                        'ipc_pvc', 'ipc_viv', 'ipc_bsd', 'ipc_edu', 'itcr',  'itcr_arg', 'itcr_bra', 'itcr_chl', 'itcr_col',\n",
    "                                        'p_gas', 'p_soya_sem', 'p_soya_act', 'p_soya_hrn', 'p_banana', 'p_cobre', 'p_estano', 'p_zinc',\n",
    "                                        'itri', 'iint', 'iadu', 'gsep', 'gbys', 'gint', 'gcap', \n",
    "                                        'yield10y_2y', 'yield10y_3m', 'index_pro_ind', 'vix', 'fed_funds_nom', 'long_term_10y', 'oecd_norm'\n",
    "                                        ]]\n",
    "                                        \n",
    "# Adding Lags of Features Selected\n",
    "for col in df_dataset_ons0_all.drop(['recession', 'recession_lag_1', 'past6_recession', 'past12_recession'], axis=1):\n",
    "    for n in [3,6]:\n",
    "        df_dataset_ons0_all['{} {}M lag'.format(col, n)] = df_dataset_ons0_all[col].shift(n).ffill().values\n",
    "        \n",
    "df_dataset_ons0_all = df_dataset_ons0_all.dropna(axis=0)\n",
    "#df_dataset_ons0_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================#\n",
    "# # Select the Sector # #\n",
    "#=======================#\n",
    "#df_dataset_ons0_real\n",
    "#df_dataset_ons0_mon\n",
    "#df_dataset_ons0_pxr\n",
    "#df_dataset_ons0_pex\n",
    "#df_dataset_ons0_fis\n",
    "#df_dataset_ons0_int\n",
    "#df_dataset_ons0_all\n",
    "df_dataset_ons0 = df_dataset_ons0_real\n",
    "df_dataset_ons0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "+ Assigning 75% of data as training set and 30 % as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dates - Accordind the previos Lags 3,6,9,12,18\n",
    "df_targets = df_dataset_ons0['recession'].values\n",
    "df_features = df_dataset_ons0.drop(['recession'], axis=1)\n",
    "\n",
    "df_training_features = df_dataset_ons0[:'2017-06-01'].drop(['recession'], axis=1)\n",
    "df_validation_features = df_dataset_ons0['2017-07-01':].drop(['recession'], axis=1)\n",
    "\n",
    "df_training_targets = df_dataset_ons0[:'2017-06-01']['recession'].values\n",
    "df_validation_targets = df_dataset_ons0['2017-07-01':]['recession'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and development (internal validation)\n",
    "xtr = df_dataset_ons0[:'2003-06-01']\n",
    "ytr = df_dataset_ons0[:'2003-06-01']['recession'].values\n",
    "xdev = df_dataset_ons0['2003-07-01':'2017-06-01']\n",
    "ydev = df_dataset_ons0['2003-07-01':'2017-06-01']['recession'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_training_features),len(df_training_targets),len(df_targets))\n",
    "print(len(df_validation_features),len(df_validation_targets),len(df_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "+ As the dataset is too small and recessions are in continuous in time series, we cannot use cross validation functions as folds with only one class will be formed.\n",
    "\n",
    "+ Thus, loop and iteration of hyperparamets is done in hypertuning Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for modelling\n",
    "#!pip install xgboost\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=8\n",
    "scoring='roc_auc' \n",
    "kfold = model_selection.TimeSeriesSplit(n_splits=2) \n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(C=1e05)))\n",
    "#models.append(('LR', LogisticRegression(C=1e09)))\n",
    "models.append(('LR_L1', LogisticRegression(penalty = 'l1',solver='liblinear')))\n",
    "models.append(('LR_L2', LogisticRegression(penalty = 'l2')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('GB', GradientBoostingClassifier()))\n",
    "models.append(('ABC', AdaBoostClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('XGB', xgb.XGBClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "for name, model in models:\n",
    "    cv_results = model_selection.cross_val_score(estimator = model, X = df_training_features, \n",
    "                                                 y = lb.fit_transform(df_training_targets), cv=kfold, scoring = scoring)\n",
    "    \n",
    "    model.fit(df_training_features, df_training_targets) # train the model\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(df_training_targets, model.predict_proba(df_training_features)[:,1])\n",
    "    auc = metrics.roc_auc_score(df_training_targets,model.predict(df_training_features))\n",
    "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (name, auc))\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity(False Positive Rate)')\n",
    "plt.ylabel('Sensitivity(True Positive Rate)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show() \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 1 y split 2\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison based on Cross Validation Scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "C = np.reciprocal([0.00000001, 0.00000005, 0.0000001, 0.0000005, 0.000001, 0.000005, 0.00001, 0.00005, \n",
    "                         0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000])\n",
    "penalty = ['l1','l2']\n",
    "\n",
    "penals = pd.DataFrame(index=penalty)\n",
    "cs = []\n",
    "scrs = []\n",
    "for p in penalty:\n",
    "        scores = []\n",
    "        params = pd.DataFrame(index=C)\n",
    "        for c in C:\n",
    "            model = LogisticRegression(C=c, max_iter=10000, penalty=p, solver='liblinear')\n",
    "            lr1 = model.fit(xtr,ytr)\n",
    "            ypreds = lr1.predict(xdev)\n",
    "            score = roc_auc_score(ydev,ypreds)\n",
    "            scores.append(score)\n",
    "        params['rocauc'] = scores\n",
    "        maxc = params['rocauc'].idxmax()\n",
    "        maxsc = params['rocauc'].max()\n",
    "        scrs.append(maxsc)\n",
    "        cs.append(maxc)\n",
    "penals['C'] = cs\n",
    "penals['score'] = scrs\n",
    "penals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.1, penalty='l2', max_iter=10000, solver='liblinear')\n",
    "#model = LogisticRegression(C=0.100, penalty='l2', max_iter=10000, solver='liblinear')\n",
    "#model = LogisticRegression(C=0.002, penalty='l2', max_iter=10000, solver='liblinear')\n",
    "lr2 = model.fit(df_training_features, df_training_targets)\n",
    "ypreds = lr2.predict(df_validation_features)\n",
    "param = lr2.get_params()\n",
    "score = roc_auc_score(df_validation_targets, ypreds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8\n",
    "scoring = 'roc_auc' \n",
    "kfold = model_selection.TimeSeriesSplit(n_splits=2) \n",
    "lb = preprocessing.LabelBinarizer()\n",
    "xgboost = model_selection.GridSearchCV(estimator=xgb.XGBClassifier(),\n",
    "                                       param_grid={'booster': ['gbtree'],\n",
    "                                                  'max_depth':[2,3,5,10],\n",
    "                                                  'learning_rate':[0.01,0.1,1]},\n",
    "                                       scoring=scoring, cv=kfold).fit(df_training_features, \n",
    "                                                                      lb.fit_transform(df_training_targets)).best_estimator_\n",
    "xgboost.fit(df_training_features, df_training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxg = xgb.XGBClassifier(learning_rate=0.001,n_estimators=1000,max_depth=100,booster='gbtree',n_jobs=-1).fit(df_training_features, df_training_targets)\n",
    "ypredsxgb = modelxg.predict(df_validation_features)\n",
    "\n",
    "xgbscore = roc_auc_score(df_validation_targets,ypredsxgb)\n",
    "xgbscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# define periods of recession\n",
    "rec_spans = []\n",
    "\n",
    "# Date format: YYYY-MM-DD\n",
    "rec_spans.append([datetime.datetime(1994,9,1), datetime.datetime(1994,12,1)])\n",
    "rec_spans.append([datetime.datetime(1995,4,1), datetime.datetime(1995,4,1)])\n",
    "rec_spans.append([datetime.datetime(1998,10,1), datetime.datetime(1999,6,1)])\n",
    "rec_spans.append([datetime.datetime(2001,12,1), datetime.datetime(2002,2,1)])\n",
    "rec_spans.append([datetime.datetime(2004,8,1), datetime.datetime(2004,11,1)])\n",
    "\n",
    "rec_spans.append([datetime.datetime(2005,5,1), datetime.datetime(2005,10,1)])\n",
    "rec_spans.append([datetime.datetime(2006,1,1), datetime.datetime(2006,1,1)])\n",
    "rec_spans.append([datetime.datetime(2008,8,1), datetime.datetime(2008,11,1)])\n",
    "\n",
    "rec_spans.append([datetime.datetime(2018,9,1), datetime.datetime(2018,12,1)])\n",
    "rec_spans.append([datetime.datetime(2019,7,1), datetime.datetime(2019,11,1)])\n",
    "rec_spans.append([datetime.datetime(2020,2,1), datetime.datetime(2020,4,1)])\n",
    "rec_spans.append([datetime.datetime(2020,12,1), datetime.datetime(2021,2,1)])\n",
    "rec_spans.append([datetime.datetime(2022,7,1), datetime.datetime(2022,11,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_predictions = lr2.predict_proba(df_training_features)\n",
    "prob_predictions = np.append(prob_predictions, lr2.predict_proba(df_validation_features), axis=0)\n",
    "sample_range = pd.date_range(start='7/1/1991', end='11/1/2023', freq='MS') # MM/DD/YYY\n",
    "#sample_range = pd.date_range(start='1/1/1991', end='11/1/2023', freq='MS') ### Before the included lags\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(sample_range.to_series().values, prob_predictions[:,0])\n",
    "for i in range(len(rec_spans)):\n",
    "    plt.axvspan(rec_spans[i][0], rec_spans[i][len(rec_spans[i]) - 1], alpha=0.25, color='grey')\n",
    "plt.axhline(y=0.5, color='r', ls='dashed', alpha = 0.5)\n",
    "plt.title('Recession Prediction Probabalities with Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install shap\n",
    "import shap\n",
    "# load your data here, e.g. X and y\n",
    "# create and fit your model here\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
    "explainer = shap.LinearExplainer(lr2,df_training_features)\n",
    "shap_values = explainer.shap_values(df_training_features.values)\n",
    "\n",
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "#shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])\n",
    "\n",
    "shap.summary_plot(shap_values, df_training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
